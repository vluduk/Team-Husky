{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ca5d7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b0e5cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# ========= Device =========\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# ========= Data Preparation =========\n",
    "df = pd.read_csv('Train_timeseries_filled.csv')\n",
    "df = df.loc[:100_000]\n",
    "\n",
    "\n",
    "class Seq2SeqDataset(Dataset):\n",
    "    def __init__(self, data, hist_len=240, fut_len=240):\n",
    "        self.X = torch.tensor(data.values, dtype=torch.float32)\n",
    "        self.hist, self.fut = hist_len, fut_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X) - self.hist - self.fut + 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.X[idx:idx+self.hist]              # (hist, 6)\n",
    "        y = self.X[idx+self.hist:idx+self.hist+self.fut]  # (fut, 6)\n",
    "        return x, y\n",
    "\n",
    "hist_len, fut_len = 240, 240\n",
    "dataset = Seq2SeqDataset(df, hist_len, fut_len)\n",
    "\n",
    "# 80/20 split\n",
    "train_size = int(len(dataset) * 0.8)\n",
    "test_size = len(dataset) - train_size\n",
    "train_ds, test_ds = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=False, pin_memory=True)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=64, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f80eddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= Model =========\n",
    "class RNNSeq2Seq(nn.Module):\n",
    "    def __init__(self, input_dim=6, hidden_dim=64, num_layers=2, fut_len=240):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.RNN(input_dim, hidden_dim, num_layers,\n",
    "                              batch_first=True, bidirectional=False)\n",
    "        self.decoder = nn.RNN(input_dim, hidden_dim, num_layers,\n",
    "                              batch_first=True, bidirectional=False)\n",
    "        self.proj = nn.Linear(hidden_dim, input_dim)\n",
    "        self.fut_len = fut_len\n",
    "\n",
    "    def forward(self, src):\n",
    "        # src: (B, hist_len, 6)\n",
    "        _, h = self.encoder(src)  # h: (num_layers, B, hidden_dim)\n",
    "        # start decoder with last observed value\n",
    "        dec_input = src[:, -1:, :]  # (B, 1, 6)\n",
    "        outputs = []\n",
    "        for _ in range(self.fut_len):\n",
    "            out, h = self.decoder(dec_input, h)\n",
    "            val = self.proj(out)          # (B, 1, 6)\n",
    "            outputs.append(val)\n",
    "            dec_input = val               # feed back\n",
    "        return torch.cat(outputs, dim=1)  # (B, fut_len, 6)\n",
    "\n",
    "model = RNNSeq2Seq(input_dim=6, hidden_dim=64, num_layers=2, fut_len=fut_len)\n",
    "model = model.to(device)\n",
    "\n",
    "# ========= Training & Evaluation =========\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.MSELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36e6250c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for xb, yb in train_loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(xb)\n",
    "        loss = criterion(pred, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_epoch():\n",
    "    model.eval()\n",
    "    preds, truths = [], []\n",
    "    for xb, yb in test_loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        out = model(xb)\n",
    "        preds.append(out.cpu().numpy().reshape(-1,6))\n",
    "        truths.append(yb.cpu().numpy().reshape(-1,6))\n",
    "    preds = np.vstack(preds)\n",
    "    truths = np.vstack(truths)\n",
    "    return (\n",
    "        mean_squared_error(truths, preds),\n",
    "        mean_absolute_error(truths, preds),\n",
    "        r2_score(truths, preds)\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b47909a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 | Train MSE Loss: 1.7121 | Test MSE: 1.6904 | MAE: 0.9811 | R2: 0.2102\n",
      "Epoch 2/10 | Train MSE Loss: 1.7518 | Test MSE: 1.9032 | MAE: 1.0643 | R2: 0.1119\n",
      "Epoch 3/10 | Train MSE Loss: 1.8217 | Test MSE: 1.7683 | MAE: 1.0091 | R2: 0.1732\n",
      "Epoch 4/10 | Train MSE Loss: 1.7364 | Test MSE: 1.7664 | MAE: 1.0091 | R2: 0.1742\n",
      "Epoch 5/10 | Train MSE Loss: 1.7326 | Test MSE: 1.7021 | MAE: 0.9865 | R2: 0.2035\n",
      "Epoch 6/10 | Train MSE Loss: 1.6971 | Test MSE: 1.7021 | MAE: 0.9850 | R2: 0.2043\n",
      "Epoch 7/10 | Train MSE Loss: 1.7117 | Test MSE: 1.7126 | MAE: 0.9891 | R2: 0.1994\n",
      "Epoch 8/10 | Train MSE Loss: 1.6981 | Test MSE: 1.6983 | MAE: 0.9817 | R2: 0.2060\n",
      "Epoch 9/10 | Train MSE Loss: 1.7347 | Test MSE: 1.8014 | MAE: 1.0268 | R2: 0.1581\n",
      "Epoch 10/10 | Train MSE Loss: 1.6324 | Test MSE: 1.5345 | MAE: 0.9149 | R2: 0.2816\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for ep in range(1, epochs+1):\n",
    "    train_loss = train_epoch()\n",
    "    mse, mae, r2 = eval_epoch()\n",
    "    print(f\"Epoch {ep}/{epochs} | Train MSE Loss: {train_loss:.4f} | \"\n",
    "          f\"Test MSE: {mse:.4f} | MAE: {mae:.4f} | R2: {r2:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
