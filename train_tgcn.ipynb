{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading dataset (30000 samples)...\n",
            "Number of features: 76, Number of targets: 6\n",
            "Creating 4 environments...\n",
            "Training TGCN model...\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint64, uint32, uint16, uint8, and bool.",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[49]\u001b[39m\u001b[32m, line 291\u001b[39m\n\u001b[32m    289\u001b[39m \u001b[38;5;66;03m# Train TGCN model\u001b[39;00m\n\u001b[32m    290\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTraining TGCN model...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m291\u001b[39m \u001b[43mtrain_tgcn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_envs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    293\u001b[39m \u001b[38;5;66;03m# Save the trained model\u001b[39;00m\n\u001b[32m    294\u001b[39m model_path = \u001b[33m\"\u001b[39m\u001b[33mtgcn_timeseries_240step_model.pt\u001b[39m\u001b[33m\"\u001b[39m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[49]\u001b[39m\u001b[32m, line 204\u001b[39m, in \u001b[36mtrain_tgcn\u001b[39m\u001b[34m(model, env, epochs, batch_size)\u001b[39m\n\u001b[32m    202\u001b[39m \u001b[38;5;66;03m# Convert to tensors\u001b[39;00m\n\u001b[32m    203\u001b[39m obs_tensor = torch.FloatTensor(obs_batch)\n\u001b[32m--> \u001b[39m\u001b[32m204\u001b[39m target_tensor = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mFloatTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[32m    207\u001b[39m predictions = model(obs_tensor)\n",
            "\u001b[31mTypeError\u001b[39m: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint64, uint32, uint16, uint8, and bool."
          ]
        }
      ],
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from gym.spaces import Box\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from gym.vector import SyncVectorEnv\n",
        "\n",
        "\n",
        "class TimeSeriesPredictionEnv(gym.Env):\n",
        "    \"\"\"Last 6 columns are targets, rest are features.\"\"\"\n",
        "    def __init__(self, data: pd.DataFrame, train_ratio: float = 0.8, forecast_horizon: int = 240):\n",
        "        super().__init__()\n",
        "        self.forecast_horizon = forecast_horizon\n",
        "        self.data = data.reset_index(drop=True)\n",
        "        self.scaler = StandardScaler()\n",
        "        \n",
        "        # Feature/target split  \n",
        "        self.n_targets = 6\n",
        "        self.feature_cols = data.columns[:-self.n_targets].tolist()\n",
        "        self.target_cols = data.columns[-self.n_targets:].tolist()\n",
        "        \n",
        "        # Train/test split\n",
        "        train_size = int(len(data) * train_ratio)\n",
        "        train_df = data.iloc[:train_size]\n",
        "        test_df = data.iloc[train_size:]\n",
        "        \n",
        "        # Fit & transform\n",
        "        X_train, X_test = train_df[self.feature_cols], test_df[self.feature_cols]\n",
        "        self.scaler.fit(X_train)\n",
        "        self.scaled_train_X = self.scaler.transform(X_train)\n",
        "        self.scaled_test_X = self.scaler.transform(X_test)\n",
        "        self.train_y, self.test_y = train_df[self.target_cols].values, test_df[self.target_cols].values\n",
        "        \n",
        "        # Spaces\n",
        "        obs_dim = len(self.feature_cols)\n",
        "        self.observation_space = Box(low=-20.0, high=20.0, shape=(obs_dim,), dtype=np.float32)\n",
        "        self.action_space = Box(low=-20.0, high=20.0, shape=(self.n_targets,), dtype=np.float32)\n",
        "        \n",
        "        # RNG and initial mode\n",
        "        self._np_random = None\n",
        "        self.set_mode(is_training=True)\n",
        "    \n",
        "    @property\n",
        "    def np_random(self):\n",
        "        if self._np_random is None:\n",
        "            self._np_random = np.random.RandomState()\n",
        "        return self._np_random\n",
        "    \n",
        "    def seed(self, seed=None):\n",
        "        self._np_random = np.random.RandomState(seed)\n",
        "        return [seed]\n",
        "    \n",
        "    def set_mode(self, is_training=True):\n",
        "        self.is_training = is_training\n",
        "        self.current_x = self.scaled_train_X if is_training else self.scaled_test_X\n",
        "        self.current_y = self.train_y if is_training else self.test_y\n",
        "        self.max_steps = len(self.current_x) - 1\n",
        "        self.current_step = (self.np_random.randint(0, self.max_steps) \n",
        "                            if is_training else 0)\n",
        "        return self.current_x[self.current_step]\n",
        "    \n",
        "    def reset(self, seed=None, options=None):\n",
        "        if seed is not None:\n",
        "            self.seed(seed)\n",
        "        # Ensure we have enough data for 240-step horizon\n",
        "        max_valid_start = self.max_steps - self.forecast_horizon\n",
        "        if max_valid_start < 0:\n",
        "            max_valid_start = 0\n",
        "        self.current_step = (self.np_random.randint(0, max_valid_start + 1)\n",
        "                             if self.is_training and max_valid_start > 0 else 0)\n",
        "        obs = self.current_x[self.current_step]\n",
        "        # Return target 240 steps ahead\n",
        "        target_idx = min(self.current_step + self.forecast_horizon, self.max_steps)\n",
        "        return obs, {\"target\": self.current_y[target_idx].copy()}\n",
        "    \n",
        "    def step(self, action):\n",
        "        # Get target 240 steps ahead\n",
        "        target_idx = min(self.current_step + self.forecast_horizon, self.max_steps)\n",
        "        pred, actual = action, self.current_y[target_idx]\n",
        "        reward = -np.mean((pred - actual)**2)\n",
        "        \n",
        "        self.current_step += 1\n",
        "        done = self.current_step >= self.max_steps\n",
        "        \n",
        "        if done:\n",
        "            self.current_step = (self.np_random.randint(0, self.max_steps) \n",
        "                                if self.is_training else 0)\n",
        "            \n",
        "        obs = self.current_x[self.current_step]\n",
        "        return obs, reward, done, False, {\"target\": actual.copy()}\n",
        "\n",
        "\n",
        "class TGCN(nn.Module):\n",
        "    def __init__(self, n_features, n_targets=6, hidden_dim=64):\n",
        "        super().__init__()\n",
        "        self.n_targets = n_targets\n",
        "        self.n_features = n_features\n",
        "        \n",
        "        # Graph convolution for spatial dependencies\n",
        "        self.gcn1 = nn.Linear(n_features, hidden_dim)\n",
        "        self.gcn2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        \n",
        "        # GRU for temporal dependencies\n",
        "        self.gru = nn.GRU(hidden_dim, hidden_dim, batch_first=True)\n",
        "        \n",
        "        # Decoder for 240-step prediction\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, n_targets)  # Predict all 6 series 240 steps ahead\n",
        "        )\n",
        "        \n",
        "        # Adjacency matrix (learnable or fixed based on correlations)\n",
        "        self.adj_weight = nn.Parameter(torch.eye(n_targets))\n",
        "        \n",
        "    def forward(self, x, seq_len=60):  # Use last 60 minutes of data\n",
        "        # For single timestep input, create a sequence\n",
        "        if len(x.shape) == 2:\n",
        "            # Reshape to [batch_size, seq_len, n_features]\n",
        "            # If x is just one timestep, repeat it seq_len times\n",
        "            x = x.unsqueeze(1).repeat(1, seq_len, 1)\n",
        "        \n",
        "        # Extract last seq_len timesteps if we have more\n",
        "        if x.shape[1] > seq_len:\n",
        "            x_seq = x[:, -seq_len:, :]\n",
        "        else:\n",
        "            x_seq = x\n",
        "        \n",
        "        # Apply GCN to each timestep\n",
        "        gcn_outputs = []\n",
        "        for t in range(x_seq.shape[1]):\n",
        "            h = F.relu(self.gcn1(x_seq[:, t]))\n",
        "            h = self.gcn2(h)\n",
        "            gcn_outputs.append(h)\n",
        "            \n",
        "        gcn_out = torch.stack(gcn_outputs, dim=1)\n",
        "        \n",
        "        # Temporal modeling\n",
        "        gru_out, _ = self.gru(gcn_out)\n",
        "        \n",
        "        # Decode to predict 240 steps ahead\n",
        "        predictions = self.decoder(gru_out[:, -1])\n",
        "        \n",
        "        return predictions\n",
        "\n",
        "\n",
        "def make_env(data, train_ratio, seed, forecast_horizon):\n",
        "    def _init():\n",
        "        env = TimeSeriesPredictionEnv(data, train_ratio, forecast_horizon)\n",
        "        env.seed(seed)\n",
        "        return env\n",
        "    return _init\n",
        "\n",
        "\n",
        "def train_tgcn(model, env, epochs=50, batch_size=32):\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "    model.train()\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        for _ in range(100):  # 100 batches per epoch\n",
        "            # Reset the environment\n",
        "            obs, info = env.reset()\n",
        "            \n",
        "            # Handle vectorized environment output\n",
        "            if isinstance(obs, np.ndarray) and obs.ndim > 1:\n",
        "                # Observation is already batched\n",
        "                obs_batch = obs[:batch_size]\n",
        "                \n",
        "                # Extract targets from info - SyncVectorEnv returns a list of dicts\n",
        "                if isinstance(info, list):\n",
        "                    # Extract target arrays from the list of dictionaries\n",
        "                    target_list = [item['target'] for item in info[:batch_size]]\n",
        "                    # Stack them into a single numpy array\n",
        "                    target_batch = np.stack(target_list, axis=0)\n",
        "                else:\n",
        "                    # Single environment case\n",
        "                    target_batch = info['target']\n",
        "                    if target_batch.ndim == 1:\n",
        "                        target_batch = target_batch.reshape(1, -1)\n",
        "            else:\n",
        "                # Non-vectorized environment - shouldn't happen with SyncVectorEnv\n",
        "                obs_batch = []\n",
        "                target_batch = []\n",
        "                for _ in range(batch_size):\n",
        "                    obs, info = env.reset()\n",
        "                    obs_batch.append(obs)\n",
        "                    target_batch.append(info['target'])\n",
        "                obs_batch = np.array(obs_batch)\n",
        "                target_batch = np.stack(target_batch, axis=0)\n",
        "            \n",
        "            # Ensure we have the right batch size\n",
        "            actual_batch_size = min(batch_size, obs_batch.shape[0])\n",
        "            obs_batch = obs_batch[:actual_batch_size]\n",
        "            target_batch = target_batch[:actual_batch_size]\n",
        "            \n",
        "            # Convert to tensors\n",
        "            obs_tensor = torch.FloatTensor(obs_batch)\n",
        "            target_tensor = torch.FloatTensor(target_batch)\n",
        "            \n",
        "            # Forward pass\n",
        "            predictions = model(obs_tensor)\n",
        "            loss = F.mse_loss(predictions, target_tensor)\n",
        "            \n",
        "            # Backward pass\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            total_loss += loss.item()\n",
        "        \n",
        "        print(f\"Epoch {epoch}: Loss = {total_loss/100:.4f}\")\n",
        "\n",
        "\n",
        "def test_tgcn_240_ahead(env, model, episodes=5):\n",
        "    model.eval()\n",
        "    mse_scores = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for episode in range(episodes):\n",
        "            done = False\n",
        "            obs, info = env.reset()\n",
        "            \n",
        "            # Handle vectorized environments\n",
        "            if isinstance(obs, np.ndarray) and obs.ndim > 1:\n",
        "                # Take first env for testing\n",
        "                obs = obs[0]\n",
        "                if isinstance(info, list):\n",
        "                    info = info[0]\n",
        "            \n",
        "            while not done:\n",
        "                # Predict 240 steps ahead\n",
        "                obs_tensor = torch.FloatTensor(obs).unsqueeze(0)\n",
        "                pred = model(obs_tensor).squeeze().numpy()\n",
        "                \n",
        "                # Step\n",
        "                next_obs, reward, done, _, next_info = env.step(pred)\n",
        "                \n",
        "                # Handle vectorized environments\n",
        "                if isinstance(next_obs, np.ndarray) and next_obs.ndim > 1:\n",
        "                    next_obs = next_obs[0]\n",
        "                    done = done[0]\n",
        "                    if isinstance(next_info, list):\n",
        "                        next_info = next_info[0]\n",
        "                \n",
        "                actual = next_info['target']\n",
        "                mse = np.mean((pred - actual)**2)\n",
        "                mse_scores.append(mse)\n",
        "                \n",
        "                obs = next_obs\n",
        "                info = next_info\n",
        "    \n",
        "    print(f\"Average MSE over {episodes} episodes: {np.mean(mse_scores):.4f}\")\n",
        "    return np.mean(mse_scores)\n",
        "\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    # Configuration\n",
        "    data_samples = 30_000\n",
        "    num_envs = 4\n",
        "    train_ratio = 0.8\n",
        "    forecast_horizon = 240\n",
        "    epochs = 1\n",
        "    \n",
        "    # Load data\n",
        "    print(f\"Loading dataset ({data_samples} samples)...\")\n",
        "    data = pd.read_csv(\"X.csv\")\n",
        "    data = data[:data_samples]\n",
        "    \n",
        "    # Determine number of features (all columns except last 6)\n",
        "    n_features = data.shape[1] - 6\n",
        "    print(f\"Number of features: {n_features}, Number of targets: 6\")\n",
        "    \n",
        "    # Make environments with 240-step forecast horizon\n",
        "    print(f\"Creating {num_envs} environments...\")\n",
        "    env_fns = [make_env(data, train_ratio, seed=i, forecast_horizon=forecast_horizon) \n",
        "               for i in range(num_envs)]\n",
        "    env = SyncVectorEnv(env_fns)\n",
        "    \n",
        "    # Initialize TGCN model\n",
        "    model = TGCN(n_features=n_features, n_targets=6, hidden_dim=64)\n",
        "    \n",
        "    # Train TGCN model\n",
        "    print(\"Training TGCN model...\")\n",
        "    train_tgcn(model, env, epochs=epochs, batch_size=num_envs)\n",
        "    \n",
        "    # Save the trained model\n",
        "    model_path = \"tgcn_timeseries_240step_model.pt\"\n",
        "    torch.save(model.state_dict(), model_path)\n",
        "    print(f\"Model saved to: {model_path}\")\n",
        "    \n",
        "    # Test the model\n",
        "    print(\"\\nTesting the trained model...\")\n",
        "    test_tgcn_240_ahead(env, model, episodes=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
